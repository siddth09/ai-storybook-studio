<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AI Storybook Adventure</title>
<script src="https://cdn.tailwindcss.com"></script>
<!-- Tesseract.js (Open Source OCR) is now loaded here to run client-side -->
<script src='https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js'></script>
<!-- PDF.js Libraries for client-side PDF rendering -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.min.js"></script>
<style>
  body { font-family: 'Inter', sans-serif; background-color: #f0f4f8; }
  .storybook-page { box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1),0 4px 6px -2px rgba(0,0,0,0.05); transition: transform 0.3s ease-in-out; transform-style: preserve-3d; }
  .loader-dot { animation: pulse 1.5s infinite; }
  .loader-dot:nth-child(2){animation-delay:0.5s;}
  .loader-dot:nth-child(3){animation-delay:1s;}
  @keyframes pulse {0%,100%{opacity:1;}50%{opacity:0.5;}}
</style>
</head>
<body>
<div id="app" class="min-h-screen flex flex-col items-center p-4 sm:p-8">
  <!-- Logo -->
  <img src="https://raw.githubusercontent.com/siddth09/storybookai-backend/main/public/logo.png" 
       alt="StoryBook AI Logo" 
       class="w-32 h-auto mb-4">

  <h1 class="text-3xl sm:text-4xl font-extrabold text-blue-800 mb-6 text-center">
    StoryBook AI - A Storybook Studio
  </h1>

<div id="input-area" class="w-full max-w-xl bg-white p-6 rounded-xl shadow-lg mb-8">
  <p class="text-sm text-gray-500 mb-4">
    Tell me what your story is about (e.g., 'A friendly alien who lost his dog on the moon').
  </p>
  <textarea id="story-prompt" rows="3" class="w-full p-3 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500 transition resize-none" placeholder="Enter your story idea..."></textarea>
  
  <div class="mt-4 flex flex-col sm:flex-row gap-3">
    <button id="record-button" class="flex-1 py-3 bg-blue-500 text-white font-bold rounded-lg hover:bg-blue-600 transition shadow-md flex items-center justify-center">
      üéôÔ∏è Speak My Idea
    </button>
    
    <label for="doc-upload" class="flex-1 py-3 bg-purple-500 text-white font-bold rounded-lg hover:bg-purple-600 transition shadow-md flex items-center justify-center cursor-pointer">
      üìÑ Upload Document
    </label>
    <!-- UPDATED: Added .pdf support -->
    <input id="doc-upload" type="file" accept=".jpg,.jpeg,.png,.pdf" class="hidden" />
  </div>

  <p id="status-message" class="text-sm text-gray-600 mt-2 text-center"></p>

  <button id="generate-button" onclick="startGeneration()" class="w-full mt-4 py-3 bg-green-500 text-white font-bold rounded-lg hover:bg-green-600 transition shadow-md disabled:bg-gray-400">
    Generate My Story!
  </button>
</div>

<div id="story-container" class="w-full max-w-4xl relative min-h-[60vh] flex justify-center">
  <div id="loading-state" class="absolute inset-0 flex flex-col items-center justify-center bg-white/90 z-10 hidden rounded-xl shadow-2xl p-8">
    <div class="flex space-x-2">
      <div class="loader-dot w-4 h-4 bg-blue-500 rounded-full"></div>
      <div class="loader-dot w-4 h-4 bg-green-500 rounded-full"></div>
      <div class="loader-dot w-4 h-4 bg-yellow-500 rounded-full"></div>
    </div>
    <p id="loading-message" class="mt-4 text-xl font-semibold text-gray-700 text-center">Generating Story Pages...</p>
    <div id="progress-bar" class="w-full max-w-sm mt-4 h-2 bg-gray-200 rounded-full overflow-hidden">
      <div id="progress-fill" class="h-full bg-blue-500 transition-all duration-500 ease-in-out" style="width:0%;"></div>
    </div>
  </div>

  <div id="page-view" class="storybook-page w-full h-full bg-white rounded-xl shadow-2xl p-4 sm:p-8 flex flex-col hidden">
    <h2 id="story-title" class="text-2xl font-bold text-center text-blue-700 mb-4"></h2>
    <div class="flex-grow flex flex-col sm:flex-row items-center sm:items-start space-y-4 sm:space-y-0 sm:space-x-8">
      <div class="w-full sm:w-1/2 flex justify-center">
        <img id="page-image" src="https://placehold.co/400x300/e0f7fa/00bcd4?text=Illustration+Loading" alt="Story illustration" class="w-full h-auto max-h-[50vh] object-contain rounded-lg border-4 border-blue-100 shadow-md">
      </div>
      <div class="w-full sm:w-1/2 flex flex-col justify-between h-full">
        <div class="text-area">
          <p id="page-number-display" class="text-sm font-medium text-gray-500 mb-2"></p>
          <p id="page-text" class="text-lg text-gray-800 leading-relaxed font-serif"></p>
        </div>
        <div class="mt-6 flex flex-col space-y-3">
          <button id="narration-button" onclick="toggleNarration()" class="py-3 bg-yellow-500 text-white font-bold rounded-lg hover:bg-yellow-600 transition shadow-md flex items-center justify-center disabled:bg-gray-400">Read This Page Aloud</button>
          <div class="flex space-x-4">
            <button id="prev-button" onclick="navigateStory(-1)" class="flex-1 py-3 bg-blue-500 text-white font-bold rounded-lg hover:bg-blue-600 transition shadow-md disabled:bg-gray-400 flex items-center justify-center">Previous</button>
            <button id="next-button" onclick="navigateStory(1)" class="flex-1 py-3 bg-blue-500 text-white font-bold rounded-lg hover:bg-blue-600 transition shadow-md disabled:bg-gray-400 flex items-center justify-center">Next</button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div id="error-box" class="fixed bottom-4 right-4 bg-red-500 text-white p-4 rounded-lg shadow-xl hidden" role="alert">
  <p id="error-text"></p>
</div>

</div>

<script>
// Global State and Elements
let storyData = null;
let currentPage = 0;
let audioPlayer = new Audio();
let isReading = false;

const storyPromptEl = document.getElementById('story-prompt');
const generateButton = document.getElementById('generate-button');
const loadingState = document.getElementById('loading-state');
const loadingMessage = document.getElementById('loading-message');
const pageView = document.getElementById('page-view');
const storyTitleEl = document.getElementById('story-title');
const pageNumberDisplay = document.getElementById('page-number-display');
const pageImage = document.getElementById('page-image');
const pageText = document.getElementById('page-text');
const prevButton = document.getElementById('prev-button');
const nextButton = document.getElementById('next-button');
const narrationButton = document.getElementById('narration-button');
const progressBarFill = document.getElementById('progress-fill');

// Elements for STT/Document Upload
const recordButton = document.getElementById('record-button');
const docUploadInput = document.getElementById('doc-upload');
const statusMessage = document.getElementById('status-message');

// Base path for API calls, using window.location.origin to ensure absolute path resolution
const API_BASE_PATH = window.location.origin;

// Set PDF.js worker source globally
if (window.pdfjsLib) {
    window.pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.worker.min.js';
}

// --- API Configuration ---
const API_KEY = ""; // Canvas will automatically provide this
const STORY_MODEL_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=${API_KEY}`;
const TTS_MODEL_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${API_KEY}`;
const IMAGE_MODEL_URL = `https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${API_KEY}`;

// Define the desired number of pages for the story
const STORY_PAGE_COUNT = 3;

// --- Robust Fetch with Retry Mechanism (For all AI calls) ---

/**
 * Attempts to fetch a URL, retrying on failure with exponential backoff.
 */
async function fetchWithRetry(url, options, maxRetries = 3) {
    let lastError = null;
    for (let i = 0; i < maxRetries; i++) {
        try {
            const response = await fetch(url, options);
            
            if (!response.ok) {
                const status = response.status;
                const errorData = await response.json().catch(() => ({ error: `HTTP Error ${status}` }));
                
                if (i === maxRetries - 1 || status < 500) {
                     throw new Error(errorData.error || `HTTP Error ${status}: ${JSON.stringify(errorData)}`);
                }
                
                throw new Error(`Transient Server Error (${status}), Retrying...`);
            }
            return response;
        } catch (error) {
            lastError = error;
            if (i < maxRetries - 1) {
                const delay = Math.pow(2, i) * 1000;
                await new Promise(resolve => setTimeout(resolve, delay));
            }
        }
    }
    throw new Error(`API call failed after ${maxRetries} attempts: ${lastError ? lastError.message : 'Unknown error'}`);
}


// --- Audio Conversion Utilities (Necessary for Gemini TTS API which returns raw PCM) ---

/** Converts a base64 string to an ArrayBuffer. */
function base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
}

/** Converts PCM data (Int16Array) to a WAV Blob. */
function pcmToWav(pcm16, sampleRate = 24000) {
    const buffer = new ArrayBuffer(44 + pcm16.length * 2);
    const view = new DataView(buffer);
    let offset = 0;

    // Helper function to write to DataView
    function writeString(s) {
        for (let i = 0; i < s.length; i++) {
            view.setUint8(offset++, s.charCodeAt(i));
        }
    }
    function writeUint32(i) { view.setUint32(offset, i, true); offset += 4; }
    function writeUint16(i) { view.setUint16(offset, i, true); offset += 2; }

    // RIFF chunk descriptor
    writeString('RIFF');
    writeUint32(36 + pcm16.length * 2); // Chunk size
    writeString('WAVE');

    // fmt chunk
    writeString('fmt ');
    writeUint32(16); // Sub-chunk size
    writeUint16(1);  // Audio format (1 for PCM)
    writeUint16(1);  // Num channels (Mono)
    writeUint32(sampleRate);
    writeUint32(sampleRate * 2); // Byte rate (SampleRate * NumChannels * BitsPerSample/8)
    writeUint16(2);  // Block align (NumChannels * BitsPerSample/8)
    writeUint16(16); // Bits per sample

    // data chunk
    writeString('data');
    writeUint32(pcm16.length * 2); // Sub-chunk 2 size

    // Write PCM data
    for (let i = 0; i < pcm16.length; i++) {
        view.setInt16(offset, pcm16[i], true);
        offset += 2;
    }

    return new Blob([view], { type: 'audio/wav' });
}


// --- Utility Functions ---

function showError(message){
    const errorBox = document.getElementById('error-box');
    document.getElementById('error-text').textContent = message;
    errorBox.classList.remove('hidden');
    setTimeout(() => errorBox.classList.add('hidden'), 5000);
    console.error(message);
}

function updateLoading(message, step, totalSteps = 15){
    loadingMessage.textContent = message;
    const percent = Math.min(100, Math.round((step / totalSteps) * 100));
    progressBarFill.style.width = `${percent}%`;
}

function stopNarration(){
    audioPlayer.pause();
    audioPlayer.currentTime = 0;
    isReading = false;
    narrationButton.textContent = 'Read This Page Aloud';
    narrationButton.classList.remove('bg-red-500','hover:bg-red-600');
    narrationButton.classList.add('bg-yellow-500','hover:bg-yellow-600');
}

// --- Storybook Navigation and Audio ---

function displayPage(pageNum){
    if(!storyData || !storyData.pages.length) return;
    currentPage = pageNum;
    const pageIndex = pageNum - 1;
    const page = storyData.pages[pageIndex];
    stopNarration();
    storyTitleEl.textContent = storyData.title;
    pageNumberDisplay.textContent = `Page ${pageNum} of ${storyData.pages.length}`;
    
    // Set image source
    pageImage.src = page.imageUrl || 'https://placehold.co/400x300/e0f7fa/00bcd4?text=Illustration+Failed';
    pageText.textContent = page.text;
    
    prevButton.disabled = pageNum === 1;
    nextButton.disabled = pageNum === storyData.pages.length;
    
    if (!page.audioUrl) {
        // Handle failed audio generation
        narrationButton.textContent = 'üîä Narration Unavailable';
        narrationButton.disabled = true;
        audioPlayer.src = ''; 
    } else {
        narrationButton.textContent = 'Read This Page Aloud';
        narrationButton.disabled = false;
        audioPlayer.src = page.audioUrl;
        // Autostart narration when a page is displayed
        toggleNarration(true);
    }
}

function navigateStory(direction){
    const newPage = currentPage + direction;
    if(newPage >= 1 && newPage <= storyData.pages.length){
        displayPage(newPage);
    }
}

function toggleNarration(startImmediately = false){
    if (narrationButton.disabled) return;

    if (isReading && !startImmediately) {
        audioPlayer.pause();
        isReading = false;
        narrationButton.textContent = 'Read This Page Aloud';
        narrationButton.classList.remove('bg-red-500','hover:bg-red-600');
        narrationButton.classList.add('bg-yellow-500','hover:bg-yellow-600');
    } else if(audioPlayer.src){
        audioPlayer.play().catch(e => {
            console.error(e);
            showError("Could not play audio. User interaction may be required to start playback.");
        });
        isReading = true;
        narrationButton.textContent = 'Stop Reading';
        narrationButton.classList.remove('bg-yellow-500','hover:bg-yellow-600');
        narrationButton.classList.add('bg-red-500','hover:bg-red-600');
    }
}

audioPlayer.addEventListener('ended', stopNarration);


// --- LIVE Story Generation Function (Uses direct Gemini API Calls) ---

async function startGeneration(){
    const prompt = storyPromptEl.value.trim();
    if(!prompt) return showError("Please enter a story idea!");
    
    storyData = null;
    currentPage = 0;
    pageView.classList.add('hidden');
    loadingState.classList.remove('hidden');
    generateButton.disabled = true;
    generateButton.textContent = 'Generating...';
    
    let step = 0;
    
    try{
        // 1. Generate Story Structure (Text, Image Prompts, Titles)
        updateLoading("1/3: Writing story structure with Gemini...", step++);

        const storyPayload = {
            contents: [{ parts: [{ text: `Create a short, ${STORY_PAGE_COUNT}-page children's story based on this idea: "${prompt}". The output MUST be a JSON object conforming to the following schema. The image_prompt should be highly descriptive and suitable for an illustration model.` }] }],
            generationConfig: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: "OBJECT",
                    properties: {
                        "title": { "type": "STRING", "description": "A catchy title for the story." },
                        "pages": {
                            "type": "ARRAY",
                            "items": {
                                "type": "OBJECT",
                                "properties": {
                                    "page_number": { "type": "INTEGER" },
                                    "text": { "type": "STRING", "description": "The story text for this page (2-3 sentences max)." },
                                    "image_prompt": { "type": "STRING", "description": "A descriptive prompt for an image generator to illustrate this page." }
                                }
                            }
                        }
                    }
                }
            }
        };

        const storyRes = await fetchWithRetry(STORY_MODEL_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(storyPayload)
        });
        
        const storyResult = await storyRes.json();
        const jsonText = storyResult.candidates?.[0]?.content?.parts?.[0]?.text;
        
        if (!jsonText) {
            throw new Error("Gemini returned no valid JSON content.");
        }
        
        const storyJson = JSON.parse(jsonText);
        
        if (!storyJson.pages || storyJson.pages.length === 0) {
            throw new Error("Gemini returned an empty or invalid story structure.");
        }
        
        storyData = storyJson;
        const totalPages = storyData.pages.length;
        const totalSteps = totalPages * 2 + 1; // 1 for story, 2 for (Image + TTS) per page
        
        // 2. Generate Images and TTS Audio for each page
        for (let i = 0; i < totalPages; i++) {
            const page = storyData.pages[i];
            const pageNum = i + 1;

            // Generate Image (Imagen)
            updateLoading(`2/3: Creating illustration Page ${pageNum} of ${totalPages}...`, step++);
            
            const imagePayload = { 
                instances: [{ prompt: page.image_prompt }], 
                parameters: { "sampleCount": 1 } 
            };
            
            const imgRes = await fetchWithRetry(IMAGE_MODEL_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(imagePayload)
            });
            
            const imgResult = await imgRes.json();
            const base64Img = imgResult.predictions?.[0]?.bytesBase64Encoded;

            if (base64Img) {
                page.imageUrl = `data:image/png;base64,${base64Img}`;
            } else {
                page.imageUrl = null;
                showError(`Warning: Image generation failed for page ${pageNum}.`);
            }


            // Generate TTS (Gemini TTS)
            updateLoading(`3/3: Generating narration Page ${pageNum} of ${totalPages}...`, step++);
            
            const ttsPayload = {
                contents: [{ parts: [{ text: `Say in a friendly, cheerful voice: ${page.text}` }] }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: "Puck" } // Cheerful voice
                        }
                    }
                },
                model: "gemini-2.5-flash-preview-tts"
            };

            const ttsRes = await fetchWithRetry(TTS_MODEL_URL, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(ttsPayload)
            });
            
            const ttsResult = await ttsRes.json();
            const part = ttsResult.candidates?.[0]?.content?.parts?.[0];
            const base64Audio = part?.inlineData?.data;
            const mimeType = part?.inlineData?.mimeType; // Should be audio/L16;rate=24000

            if (base64Audio && mimeType && mimeType.startsWith("audio/L16")) {
                const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                const sampleRate = sampleRateMatch ? parseInt(sampleRateMatch[1], 10) : 24000;

                // Convert PCM (Int16Array) from Base64 to ArrayBuffer to WAV Blob
                const pcmData = base64ToArrayBuffer(base64Audio);
                const pcm16 = new Int16Array(pcmData);
                const wavBlob = pcmToWav(pcm16, sampleRate);
                page.audioUrl = URL.createObjectURL(wavBlob);
            } else {
                page.audioUrl = null;
                showError(`Warning: TTS failed for page ${pageNum}.`);
            }
        }

        updateLoading("Story is ready!", totalSteps);

        setTimeout(()=>{
            displayPage(1);
            loadingState.classList.add('hidden');
            pageView.classList.remove('hidden');
            generateButton.disabled = false;
            generateButton.textContent = 'Generate My Story!';
        },500);

    } catch(e){
        showError(`Generation failed: ${e.message}`);
        loadingState.classList.add('hidden');
        generateButton.disabled = false;
        generateButton.textContent = 'Generate My Story!';
    }
}

// --- Speech-to-Text (STT) Logic ---

let recognition;
let isRecording = false;

if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'en-US';

    recognition.onstart = () => {
        isRecording = true;
        statusMessage.textContent = "üé§ Listening... Speak now!";
        recordButton.classList.add('bg-red-500', 'animate-pulse');
        recordButton.classList.remove('bg-blue-500');
        recordButton.textContent = "üõë Stop Listening";
        storyPromptEl.value = '';
    };

    recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        storyPromptEl.value = transcript;
        statusMessage.textContent = "‚úÖ Speech recorded and added to prompt.";
    };
    
    recognition.onerror = (event) => {
        if (event.error === 'no-speech') {
            statusMessage.textContent = "‚ö†Ô∏è No speech detected. Try again.";
        } else {
            showError(`Speech Recognition Error: ${event.error}`);
        }
        recognition.stop();
    };

    recognition.onend = () => {
        isRecording = false;
        recordButton.classList.remove('bg-red-500', 'animate-pulse');
        recordButton.classList.add('bg-blue-500');
        recordButton.textContent = "üéôÔ∏è Speak My Idea";
        if (statusMessage.textContent === "üé§ Listening... Speak now!") {
             statusMessage.textContent = '';
        }
    };

    recordButton.addEventListener('click', () => {
        try {
            if (isRecording) recognition.stop();
            else recognition.start();
        } catch (e) {
            console.warn("Recognition already active or stopping.", e);
        }
    });
} else {
    recordButton.disabled = true;
    recordButton.textContent = "Speech Not Supported";
    statusMessage.textContent = "‚ö†Ô∏è Speech recognition is not supported in this browser.";
}


// --- Document Upload with Client-Side Tesseract OCR Logic (Now supports PDF) ---

docUploadInput.addEventListener('change', async (event) => {
    const file = event.target.files[0];
    if (!file) return;

    statusMessage.textContent = `üìÑ Loading OCR engine...`;
    generateButton.disabled = true;

    try {
        const worker = await Tesseract.createWorker('eng', 1, {
            logger: m => {
                if (m.status === 'recognizing text') {
                    statusMessage.textContent = `üß† Recognizing text: ${(m.progress * 100).toFixed(0)}%`;
                } else if (m.status === 'loading tesseract core') {
                    statusMessage.textContent = `‚öôÔ∏è Loading Tesseract core...`;
                }
            }
        });

        let recognizedObject = file; // Default to file (for images)

        if (file.type === 'application/pdf' && window.pdfjsLib) {
            statusMessage.textContent = `üìö Preparing PDF for OCR...`;
            
            // 1. Load PDF using file reader
            const arrayBuffer = await new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsArrayBuffer(file);
            });

            const loadingTask = window.pdfjsLib.getDocument(arrayBuffer);
            const pdf = await loadingTask.promise;
            
            // 2. Get the first page
            const page = await pdf.getPage(1);
            
            // 3. Render the page to a canvas
            const scale = 2.0; // Higher scale for better OCR results
            const viewport = page.getViewport({ scale: scale });
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            canvas.height = viewport.height;
            canvas.width = viewport.width;

            statusMessage.textContent = `üñºÔ∏è Rendering PDF page to image...`;

            await page.render({ canvasContext: context, viewport: viewport }).promise;

            // Use the canvas element as the input for Tesseract
            recognizedObject = canvas;

        } else if (file.type === 'application/pdf' && !window.pdfjsLib) {
            throw new Error("PDF.js library failed to load, cannot process PDF.");
        }


        // 4. Recognize the text from the canvas (if PDF) or file (if image)
        const { data: { text } } = await worker.recognize(recognizedObject);
        
        // 5. Terminate the worker to free up resources
        await worker.terminate();
        
        const extractedText = text.trim();

        if (extractedText) {
            storyPromptEl.value = extractedText;
            statusMessage.textContent = `‚úÖ Text extracted successfully from ${file.name}!`;
        } else {
            statusMessage.textContent = "‚ö†Ô∏è No readable text found in the document.";
        }
    } catch (err) {
        // Log the full error for better diagnosis
        console.error("Tesseract/PDF OCR Error:", err);
        const errorMsg = err.message || (err.status ? `Tesseract status error: ${err.status}` : 'Unknown OCR processing error.');
        showError(`OCR failed: ${errorMsg}`);
        statusMessage.textContent = "‚ùå Failed to extract text. Please ensure the file is a clear image/PDF page.";
    } finally {
        event.target.value = ''; 
        generateButton.disabled = false;
        setTimeout(() => { statusMessage.textContent = ''; }, 7000);
    }
});


// --- Initial Setup ---
window.onload = () => {
    prevButton.disabled = true;
    nextButton.disabled = true;
    narrationButton.disabled = true;
    narrationButton.textContent = 'Read This Page Aloud';
};
</script>
</body>
</html>
