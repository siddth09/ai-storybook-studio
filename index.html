<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Storybook Studio</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body { font-family: 'Inter', sans-serif; background: #f0f4f8; color: #333; }
    .story-card { background: white; border-radius: 1rem; padding: 2rem; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-top: 2rem; }
  </style>
</head>
<body class="min-h-screen flex flex-col items-center p-6">
  <h1 class="text-3xl font-bold mb-4 text-center">📖 AI Storybook Studio</h1>
  <p class="text-gray-600 mb-6 text-center">Create magical tales using Gemini AI ✨</p>

  <div class="flex flex-col md:flex-row gap-4">
    <textarea id="prompt" class="border rounded-lg p-3 w-80 h-40" placeholder="Describe your story idea..."></textarea>
    <div class="flex flex-col gap-2">
      <button id="generateBtn" class="bg-indigo-600 text-white px-4 py-2 rounded-lg hover:bg-indigo-700">Generate Story</button>
      <button id="speakBtn" class="bg-green-500 text-white px-4 py-2 rounded-lg hover:bg-green-600">🔊 Read Aloud</button>
      <button id="listenBtn" class="bg-yellow-400 text-black px-4 py-2 rounded-lg hover:bg-yellow-500">🎙️ Speak Prompt</button>
      <input type="file" id="fileInput" class="mt-2" accept="image/*,.pdf" />
    </div>
  </div>

  <div id="output" class="story-card w-full md:w-2/3 hidden"></div>

  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4/dist/tesseract.min.js"></script>
  <script>
    const generateBtn = document.getElementById("generateBtn");
    const outputDiv = document.getElementById("output");
    const speakBtn = document.getElementById("speakBtn");
    const listenBtn = document.getElementById("listenBtn");
    const fileInput = document.getElementById("fileInput");

    // 🧠 Generate Story via Netlify Function
    generateBtn.addEventListener("click", async () => {
      const prompt = document.getElementById("prompt").value.trim();
      if (!prompt) return alert("Please enter a prompt first!");

      outputDiv.classList.remove("hidden");
      outputDiv.innerHTML = "<p>🌀 Generating your story...</p>";

      const res = await fetch("/api/generate-ai", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ prompt }),
      });

      const data = await res.json();
      if (data.error) {
        outputDiv.innerHTML = "<p class='text-red-500'>❌ " + data.error + "</p>";
      } else {
        outputDiv.innerHTML = "<h2 class='text-xl font-bold mb-2'>Your Story</h2><p>" + data.story + "</p>";
      }
    });

    // 🔊 Text-to-Speech
    speakBtn.addEventListener("click", () => {
      const text = outputDiv.innerText;
      if (!text) return alert("No story to read!");
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = "en-US";
      speechSynthesis.speak(utterance);
    });

    // 🎙️ Speech-to-Text
    listenBtn.addEventListener("click", () => {
      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = "en-US";
      recognition.start();
      recognition.onresult = (event) => {
        document.getElementById("prompt").value = event.results[0][0].transcript;
      };
    });

    // 📄 OCR Image/PDF Upload
    fileInput.addEventListener("change", async (event) => {
      const file = event.target.files[0];
      if (!file) return;

      outputDiv.classList.remove("hidden");
      outputDiv.innerHTML = "🔍 Extracting text...";

      const text = await Tesseract.recognize(file, "eng")
        .then(({ data }) => data.text)
        .catch(() => "Could not extract text.");
      document.getElementById("prompt").value = text;
      outputDiv.innerHTML = "✅ Text extracted and added to prompt!";
    });
  </script>
</body>
</html>
