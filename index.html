<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AI Storybook Adventure</title>
<script src="https://cdn.tailwindcss.com"></script>
<!-- Tesseract.js (Open Source OCR) is now loaded here to run client-side -->
<script src='https://cdn.jsdelivr.net/npm/tesseract.js@5/dist/tesseract.min.js'></script>
<!-- PDF.js Libraries for client-side PDF rendering -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.min.js"></script>
<style>
  body { font-family: 'Inter', sans-serif; background-color: #f0f4f8; }
  .storybook-page { box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1),0 4px 6px -2px rgba(0,0,0,0.05); transition: transform 0.3s ease-in-out; transform-style: preserve-3d; }
  .loader-dot { animation: pulse 1.5s infinite; }
  .loader-dot:nth-child(2){animation-delay:0.5s;}
  .loader-dot:nth-child(3){animation-delay:1s;}
  @keyframes pulse {0%,100%{opacity:1;}50%{opacity:0.5;}}
</style>
</head>
<body>
<div id="app" class="min-h-screen flex flex-col items-center p-4 sm:p-8">
  <!-- Logo -->
  <img src="https://raw.githubusercontent.com/siddth09/storybookai-backend/main/public/logo.png" 
       alt="StoryBook AI Logo" 
       class="w-32 h-auto mb-4">

  <h1 class="text-3xl sm:text-4xl font-extrabold text-blue-800 mb-6 text-center">
    StoryBook AI - A Storybook Studio
  </h1>

<div id="input-area" class="w-full max-w-xl bg-white p-6 rounded-xl shadow-lg mb-8">
  <p class="text-sm text-gray-500 mb-4">
    Tell me what your story is about (e.g., 'A friendly alien who lost his dog on the moon').
  </p>
  <textarea id="story-prompt" rows="3" class="w-full p-3 border border-gray-300 rounded-lg focus:ring-blue-500 focus:border-blue-500 transition resize-none" placeholder="Enter your story idea..."></textarea>
  
  <div class="mt-4 flex flex-col sm:flex-row gap-3">
    <button id="record-button" class="flex-1 py-3 bg-blue-500 text-white font-bold rounded-lg hover:bg-blue-600 transition shadow-md flex items-center justify-center">
      üéôÔ∏è Speak My Idea
    </button>
    
    <label for="doc-upload" class="flex-1 py-3 bg-purple-500 text-white font-bold rounded-lg hover:bg-purple-600 transition shadow-md flex items-center justify-center cursor-pointer">
      üìÑ Upload Document
    </label>
    <input id="doc-upload" type="file" accept=".jpg,.jpeg,.png,.pdf" class="hidden" />
  </div>

  <p id="status-message" class="text-sm text-gray-600 mt-2 text-center"></p>

  <button id="generate-button" onclick="startGeneration()" class="w-full mt-4 py-3 bg-green-500 text-white font-bold rounded-lg hover:bg-green-600 transition shadow-md disabled:bg-gray-400">
    Generate My Story!
  </button>
</div>

<div id="story-container" class="w-full max-w-4xl relative min-h-[60vh] flex justify-center">
  <div id="loading-state" class="absolute inset-0 flex flex-col items-center justify-center bg-white/90 z-10 hidden rounded-xl shadow-2xl p-8">
    <div class="flex space-x-2">
      <div class="loader-dot w-4 h-4 bg-blue-500 rounded-full"></div>
      <div class="loader-dot w-4 h-4 bg-green-500 rounded-full"></div>
      <div class="loader-dot w-4 h-4 bg-yellow-500 rounded-full"></div>
    </div>
    <p id="loading-message" class="mt-4 text-xl font-semibold text-gray-700 text-center">Generating Story Pages...</p>
    <div id="progress-bar" class="w-full max-w-sm mt-4 h-2 bg-gray-200 rounded-full overflow-hidden">
      <div id="progress-fill" class="h-full bg-blue-500 transition-all duration-500 ease-in-out" style="width:0%;"></div>
    </div>
  </div>

  <div id="page-view" class="storybook-page w-full h-full bg-white rounded-xl shadow-2xl p-4 sm:p-8 flex flex-col hidden">
    <h2 id="story-title" class="text-2xl font-bold text-center text-blue-700 mb-4"></h2>
    <div class="flex-grow flex flex-col sm:flex-row items-center sm:items-start space-y-4 sm:space-y-0 sm:space-x-8">
      <div class="w-full sm:w-1/2 flex justify-center">
        <img id="page-image" src="https://placehold.co/400x300/e0f7fa/00bcd4?text=Illustration+Loading" alt="Story illustration" class="w-full h-auto max-h-[50vh] object-contain rounded-lg border-4 border-blue-100 shadow-md">
      </div>
      <div class="w-full sm:w-1/2 flex flex-col justify-between h-full">
        <div class="text-area">
          <p id="page-number-display" class="text-sm font-medium text-gray-500 mb-2"></p>
          <p id="page-text" class="text-lg text-gray-800 leading-relaxed font-serif"></p>
        </div>
        <div class="mt-6 flex flex-col space-y-3">
          <button id="narration-button" onclick="toggleNarration()" class="py-3 bg-yellow-500 text-white font-bold rounded-lg hover:bg-yellow-600 transition shadow-md flex items-center justify-center disabled:bg-gray-400">Read This Page Aloud</button>
          <div class="flex space-x-4">
            <button id="prev-button" onclick="navigateStory(-1)" class="flex-1 py-3 bg-blue-500 text-white font-bold rounded-lg hover:bg-blue-600 transition shadow-md disabled:bg-gray-400 flex items-center justify-center">Previous</button>
            <button id="next-button" onclick="navigateStory(1)" class="flex-1 py-3 bg-blue-500 text-white font-bold rounded-lg hover:bg-blue-600 transition shadow-md disabled:bg-gray-400 flex items-center justify-center">Next</button>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div id="error-box" class="fixed bottom-4 right-4 bg-red-500 text-white p-4 rounded-lg shadow-xl hidden" role="alert">
  <p id="error-text"></p>
</div>

</div>

<script>
// Global State and Elements
let storyData = null;
let currentPage = 0;
let audioPlayer = new Audio();
let isReading = false;

const storyPromptEl = document.getElementById('story-prompt');
const generateButton = document.getElementById('generate-button');
const loadingState = document.getElementById('loading-state');
const loadingMessage = document.getElementById('loading-message');
const pageView = document.getElementById('page-view');
const storyTitleEl = document.getElementById('story-title');
const pageNumberDisplay = document.getElementById('page-number-display');
const pageImage = document.getElementById('page-image');
const pageText = document.getElementById('page-text');
const prevButton = document.getElementById('prev-button');
const nextButton = document.getElementById('next-button');
const narrationButton = document.getElementById('narration-button');
const progressBarFill = document.getElementById('progress-fill');

// Elements for STT/Document Upload
const recordButton = document.getElementById('record-button');
const docUploadInput = document.getElementById('doc-upload');
const statusMessage = document.getElementById('status-message');

// --- Configuration ---
// The client now calls a single Netlify Function endpoint
const NETLIFY_FUNCTION_URL = '/.netlify/functions/generate-ai';
const STORY_PAGE_COUNT = 3;


// --- Utility Functions ---

function showError(message){
    const errorBox = document.getElementById('error-box');
    document.getElementById('error-text').textContent = message;
    errorBox.classList.remove('hidden');
    setTimeout(() => errorBox.classList.add('hidden'), 5000);
    console.error(message);
}

function updateLoading(message, step, totalSteps = 15){
    loadingMessage.textContent = message;
    const percent = Math.min(100, Math.round((step / totalSteps) * 100));
    progressBarFill.style.width = `${percent}%`;
}

// --- Audio Conversion Utilities (MUST remain client-side) ---

/** Converts a base64 string to an ArrayBuffer. */
function base64ToArrayBuffer(base64) {
    const binaryString = atob(base64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
        bytes[i] = binaryString.charCodeAt(i);
    }
    return bytes.buffer;
}

/** Converts PCM data (Int16Array) to a WAV Blob. */
function pcmToWav(pcm16, sampleRate = 24000) {
    const buffer = new ArrayBuffer(44 + pcm16.length * 2);
    const view = new DataView(buffer);
    let offset = 0;

    function writeString(s) {
        for (let i = 0; i < s.length; i++) {
            view.setUint8(offset++, s.charCodeAt(i));
        }
    }
    function writeUint32(i) { view.setUint32(offset, i, true); offset += 4; }
    function writeUint16(i) { view.setUint16(offset, i, true); offset += 2; }

    // RIFF chunk descriptor
    writeString('RIFF');
    writeUint32(36 + pcm16.length * 2); // Chunk size
    writeString('WAVE');

    // fmt chunk
    writeString('fmt ');
    writeUint32(16); // Sub-chunk size
    writeUint16(1);  // Audio format (1 for PCM)
    writeUint16(1);  // Num channels (Mono)
    writeUint32(sampleRate);
    writeUint32(sampleRate * 2); // Byte rate 
    writeUint16(2);  // Block align
    writeUint16(16); // Bits per sample

    // data chunk
    writeString('data');
    writeUint32(pcm16.length * 2); // Sub-chunk 2 size

    // Write PCM data
    for (let i = 0; i < pcm16.length; i++) {
        view.setInt16(offset, pcm16[i], true);
        offset += 2;
    }

    return new Blob([view], { type: 'audio/wav' });
}


// --- Storybook Navigation and Audio ---

function stopNarration(){
    audioPlayer.pause();
    audioPlayer.currentTime = 0;
    isReading = false;
    narrationButton.textContent = 'Read This Page Aloud';
    narrationButton.classList.remove('bg-red-500','hover:bg-red-600');
    narationButton.classList.add('bg-yellow-500','hover:bg-yellow-600');
}

function displayPage(pageNum){
    if(!storyData || !storyData.pages.length) return;
    currentPage = pageNum;
    const pageIndex = pageNum - 1;
    const page = storyData.pages[pageIndex];
    stopNarration();
    storyTitleEl.textContent = storyData.title;
    pageNumberDisplay.textContent = `Page ${pageNum} of ${storyData.pages.length}`;
    
    // Set image source
    pageImage.src = page.imageUrl || 'https://placehold.co/400x300/e0f7fa/00bcd4?text=Illustration+Failed';
    pageText.textContent = page.text;
    
    prevButton.disabled = pageNum === 1;
    nextButton.disabled = pageNum === storyData.pages.length;
    
    if (!page.audioData || page.audioData.data === 'TTS_FAILED') {
        narrationButton.textContent = 'üîä Narration Unavailable';
        narrationButton.disabled = true;
        audioPlayer.src = ''; 
    } else {
        // CONVERT BASE64 PCM AUDIO TO PLAYABLE WAV BLOB HERE
        try {
            const pcmData = base64ToArrayBuffer(page.audioData.data);
            const pcm16 = new Int16Array(pcmData);
            
            // Assume 24000 sample rate, as specified in the TTS API call
            const wavBlob = pcmToWav(pcm16, 24000); 
            page.audioUrl = URL.createObjectURL(wavBlob);
            
            narrationButton.textContent = 'Read This Page Aloud';
            narrationButton.disabled = false;
            audioPlayer.src = page.audioUrl;
            toggleNarration(true);
        } catch(e) {
            showError("Audio conversion failed: " + e.message);
            narrationButton.textContent = 'üîä Narration Conversion Failed';
            narrationButton.disabled = true;
        }
    }
}

function navigateStory(direction){
    const newPage = currentPage + direction;
    if(newPage >= 1 && newPage <= storyData.pages.length){
        displayPage(newPage);
    }
}

function toggleNarration(startImmediately = false){
    if (narrationButton.disabled) return;

    if (isReading && !startImmediately) {
        audioPlayer.pause();
        isReading = false;
        narrationButton.textContent = 'Read This Page Aloud';
        narrationButton.classList.remove('bg-red-500','hover:bg-red-600');
        narrationButton.classList.add('bg-yellow-500','hover:bg-yellow-600');
    } else if(audioPlayer.src){
        audioPlayer.play().catch(e => {
            console.error(e);
            showError("Could not play audio. User interaction may be required to start playback.");
        });
        isReading = true;
        narrationButton.textContent = 'Stop Reading';
        narrationButton.classList.remove('bg-yellow-500','hover:bg-yellow-600');
        narrationButton.classList.add('bg-red-500','hover:bg-red-600');
    }
}

audioPlayer.addEventListener('ended', stopNarration);


// --- CORE GENERATION (Calls Netlify Function) ---

async function startGeneration(){
    const prompt = storyPromptEl.value.trim();
    if(!prompt) return showError("Please enter a story idea!");
    
    storyData = null;
    currentPage = 0;
    pageView.classList.add('hidden');
    loadingState.classList.remove('hidden');
    generateButton.disabled = true;
    generateButton.textContent = 'Generating...';
    
    updateLoading("Starting generation via secure serverless function...", 1);
    
    try{
        // 1. Call the Netlify Function endpoint
        const response = await fetch(NETLIFY_FUNCTION_URL, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            // Send the prompt and desired page count to the server
            body: JSON.stringify({ prompt, pageCount: STORY_PAGE_COUNT })
        });

        // 2. Check for server errors
        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Netlify Function Error (${response.status}): ${errorText.substring(0, 100)}...`);
        }

        // 3. Receive the complete story object from the function
        const finalStoryData = await response.json();
        
        if (!finalStoryData || !finalStoryData.pages || finalStoryData.pages.length === 0) {
             throw new Error("Server returned empty or invalid story data.");
        }

        storyData = finalStoryData;
        updateLoading("Story is ready! Converting audio...", 15);

        // 4. Display the first page after successful generation
        setTimeout(()=>{
            displayPage(1);
            loadingState.classList.add('hidden');
            pageView.classList.remove('hidden');
            generateButton.disabled = false;
            generateButton.textContent = 'Generate My Story!';
        }, 1000);

    } catch(e){
        showError(`Generation failed: ${e.message}`);
        loadingState.classList.add('hidden');
        generateButton.disabled = false;
        generateButton.textContent = 'Generate My Story!';
    }
}


// --- STT and OCR Logic (Unchanged and kept client-side) ---

let recognition;
let isRecording = false;

if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = 'en-US';

    recognition.onstart = () => {
        isRecording = true;
        statusMessage.textContent = "üé§ Listening... Speak now!";
        recordButton.classList.add('bg-red-500', 'animate-pulse');
        recordButton.classList.remove('bg-blue-500');
        recordButton.textContent = "üõë Stop Listening";
        storyPromptEl.value = '';
    };

    recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript;
        storyPromptEl.value = transcript;
        statusMessage.textContent = "‚úÖ Speech recorded and added to prompt.";
    };
    
    recognition.onerror = (event) => {
        if (event.error === 'no-speech') {
            statusMessage.textContent = "‚ö†Ô∏è No speech detected. Try again.";
        } else {
            showError(`Speech Recognition Error: ${event.error}`);
        }
        recognition.stop();
    };

    recognition.onend = () => {
        isRecording = false;
        recordButton.classList.remove('bg-red-500', 'animate-pulse');
        recordButton.classList.add('bg-blue-500');
        recordButton.textContent = "üéôÔ∏è Speak My Idea";
        if (statusMessage.textContent === "üé§ Listening... Speak now!") {
             statusMessage.textContent = '';
        }
    };

    recordButton.addEventListener('click', () => {
        try {
            if (isRecording) recognition.stop();
            else recognition.start();
        } catch (e) {
            console.warn("Recognition already active or stopping.", e);
        }
    });
} else {
    recordButton.disabled = true;
    recordButton.textContent = "Speech Not Supported";
    statusMessage.textContent = "‚ö†Ô∏è Speech recognition is not supported in this browser.";
}

// Set PDF.js worker source globally
if (window.pdfjsLib) {
    window.pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.worker.min.js';
}

docUploadInput.addEventListener('change', async (event) => {
    const file = event.target.files[0];
    if (!file) return;

    statusMessage.textContent = `üìÑ Loading OCR engine...`;
    generateButton.disabled = true;

    try {
        const worker = await Tesseract.createWorker('eng', 1, {
            logger: m => {
                if (m.status === 'recognizing text') {
                    statusMessage.textContent = `üß† Recognizing text: ${(m.progress * 100).toFixed(0)}%`;
                } else if (m.status === 'loading tesseract core') {
                    statusMessage.textContent = `‚öôÔ∏è Loading Tesseract core...`;
                }
            }
        });

        let recognizedObject = file;

        if (file.type === 'application/pdf' && window.pdfjsLib) {
            statusMessage.textContent = `üìö Preparing PDF for OCR...`;
            
            const arrayBuffer = await new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = () => resolve(reader.result);
                reader.onerror = reject;
                reader.readAsArrayBuffer(file);
            });

            const loadingTask = window.pdfjsLib.getDocument(arrayBuffer);
            const pdf = await loadingTask.promise;
            const page = await pdf.getPage(1);
            
            const scale = 2.0; 
            const viewport = page.getViewport({ scale: scale });
            const canvas = document.createElement('canvas');
            const context = canvas.getContext('2d');
            canvas.height = viewport.height;
            canvas.width = viewport.width;

            statusMessage.textContent = `üñºÔ∏è Rendering PDF page to image...`;

            await page.render({ canvasContext: context, viewport: viewport }).promise;
            recognizedObject = canvas;

        } else if (file.type === 'application/pdf' && !window.pdfjsLib) {
            throw new Error("PDF.js library failed to load, cannot process PDF.");
        }


        const { data: { text } } = await worker.recognize(recognizedObject);
        await worker.terminate();
        
        const extractedText = text.trim();

        if (extractedText) {
            storyPromptEl.value = extractedText;
            statusMessage.textContent = `‚úÖ Text extracted successfully from ${file.name}!`;
        } else {
            statusMessage.textContent = "‚ö†Ô∏è No readable text found in the document.";
        }
    } catch (err) {
        console.error("Tesseract/PDF OCR Error:", err);
        const errorMsg = err.message || (err.status ? `Tesseract status error: ${err.status}` : 'Unknown OCR processing error.');
        showError(`OCR failed: ${errorMsg}`);
        statusMessage.textContent = "‚ùå Failed to extract text. Please ensure the file is a clear image/PDF page.";
    } finally {
        event.target.value = ''; 
        generateButton.disabled = false;
        setTimeout(() => { statusMessage.textContent = ''; }, 7000);
    }
});


// --- Initial Setup ---
window.onload = () => {
    prevButton.disabled = true;
    nextButton.disabled = true;
    narrationButton.disabled = true;
    narrationButton.textContent = 'Read This Page Aloud';
};
</script>
</body>
</html>
